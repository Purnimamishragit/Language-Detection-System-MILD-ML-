{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd4293-f0e8-421b-a697-2e3f5004f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import speech_recognition as sr\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779dc56-da01-4e75-8d2d-560649f0432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, info = tfds.load('speech_commands', split=['train', 'validation', 'test'], with_info=True)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "dataset, info = tfds.load(\n",
    "    'speech_commands',\n",
    "    split=['train', 'validation', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "print(info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d543a93e-1f30-456e-81ba-8a67e5f502a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(dataset):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        # Audio file in the form of a tensor (waveform)\n",
    "        audio = example['audio']\n",
    "        label = example['label']\n",
    "        \n",
    "        # Convert audio to text using pre-defined mapping or classifier (optional)\n",
    "        texts.append(str(label.numpy()))  # Here we use the label as the \"language\" (i.e., command)\n",
    "        labels.append(label.numpy())\n",
    "        \n",
    "    return np.array(texts), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc7e33-8141-48f9-962e-178da6a83595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = preprocess_data(dataset[0])  # Train dataset\n",
    "val_texts, val_labels = preprocess_data(dataset[1])  # Validation dataset\n",
    "test_texts, test_labels = preprocess_data(dataset[2])  # Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6979cd-23df-4994-a3b8-f6d5b9bbe26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X_train = cv.fit_transform(train_texts)\n",
    "X_val = cv.transform(val_texts)\n",
    "X_test = cv.transform(test_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6af69b-5174-47fd-96e1-1c0eab1907e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f235dc5a-cfa0-425f-bfd9-2f457af8d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.score(X_val, val_labels)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf4b0a-e811-47a0-8c02-7846351de5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language(Enum):\n",
    "    ENGLISH = \"en\"\n",
    "\n",
    "# SpeechToText class for recording live audio input and converting it to text\n",
    "class SpeechToText:\n",
    "    @staticmethod\n",
    "    def speech_to_text(device_index=1, language=Language.ENGLISH):\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone(device_index=device_index) as source:\n",
    "            print(\"Recording...\")\n",
    "            audio = r.listen(source)\n",
    "            print(\"Recording Complete...\")\n",
    "            try:\n",
    "                # Transcribe audio to text using Google's Speech Recognition API\n",
    "                text = r.recognize_google(audio, language=language.value)\n",
    "                print(f\"Transcribed Text ({language.name}):\", text)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "                return None\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"Request error from Google Speech Recognition service: {e}\")\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa09054-1c9f-4fbd-baba-d33788a1071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_language_from_audio(device_index=1, language=Language.ENGLISH):\n",
    "    # Get the audio input and convert it to text\n",
    "    transcribed_text = SpeechToText.speech_to_text(device_index, language)\n",
    "    \n",
    "    if transcribed_text:\n",
    "        # Vectorize the transcribed text\n",
    "        data = cv.transform([transcribed_text]).toarray()\n",
    "        \n",
    "        # Predict the language (command) using the trained model\n",
    "        output = model.predict(data)\n",
    "        print(\"Predicted Language:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b2109-8481-49e8-b5d5-ad9f383f168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Predict language for a sample audio input (recorded live from the microphone)\n",
    "    device_index = 1  # Set device index based on available microphones\n",
    "    language = Language.ENGLISH  # Set language to English for recognition\n",
    "    predict_language_from_audio(device_index=device_index, language=language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
