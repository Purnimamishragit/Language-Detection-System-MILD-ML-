{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1872d796-20e5-495e-95fb-795fa14bd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import speech_recognition as sr\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "de0705ea-38f7-46b9-ab68-533e17a07f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text Language\n",
      "0   an artificial market using personal vouchers ...  English\n",
      "1  Ek krutrim bajar jaah? vyaktigata bh???ra upay...     Odia\n",
      "2  Ek krtrimik bazar jo vyakti gat vauchers ka up...    Hindi\n",
      "3  Oka krutrima maarketu, idi vyaktigata vocharlu...   Telugu\n",
      "4  Oru seyyarkai sandhai, idhu thanippatta vaucha...    Tamil\n",
      "Text        0\n",
      "Language    0\n",
      "dtype: int64\n",
      "Language\n",
      "English    30\n",
      "Odia       30\n",
      "Hindi      30\n",
      "Telugu     30\n",
      "Tamil      30\n",
      "Bengoli    30\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"Book.csv\", encoding='iso-8859-1')\n",
    "print(data.head())\n",
    "print(data.isnull().sum())\n",
    "print(data['Language'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f454e686-00e4-4634-9efd-511b556979b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "x = np.array(data['Text'])\n",
    "y = np.array(data['Language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c8b98af8-f788-416d-8957-69b281485308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4d1bc23e-012d-43b7-9730-97d07ac34c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data\n",
    "cv = CountVectorizer(max_features=5000)  # Limit features to 5000 most frequent words\n",
    "X = cv.fit_transform(x).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b52a9da1-ebc2-407f-bc08-e4fb57768dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8753fda1-b3c5-4c0e-9b5b-06f10d3123ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model (without Embedding layer)\n",
    "def create_cnn_model(input_dim):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Add Convolutional Layer\n",
    "    model.add(layers.Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=(input_dim, 1)))  # Input shape added here\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Add another Convolutional Layer\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    # Flatten the output of the convolutional layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(layers.Dense(len(label_encoder.classes_), activation='softmax'))  # Softmax for multi-class classification\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "31979000-2e4b-41f9-bebb-8fa5c0d945d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "24230a12-1211-4f3b-93a1-ae075350a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for Conv1D (need a 3D shape: [samples, timesteps, features])\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1c5b964a-ac07-4cbb-8191-00c37bd6c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2950</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1475</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1471</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">735</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47040</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010,624</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_22 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2950\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m768\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_22 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1475\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_23 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1471\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m41,024\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_23 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m735\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47040\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │       \u001b[38;5;34m3,010,624\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m390\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,806</span> (11.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,052,806\u001b[0m (11.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,052,806</span> (11.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,052,806\u001b[0m (11.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and initialize the model\n",
    "cnn_model = create_cnn_model(input_dim)\n",
    "cnn_model.summary()  # Print model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cfebe66f-9814-4c29-9c13-32252b23f0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 452ms/step - accuracy: 0.3600 - loss: 1.6588 - val_accuracy: 0.8667 - val_loss: 0.8682\n",
      "Epoch 2/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.9765 - loss: 0.4548 - val_accuracy: 0.8667 - val_loss: 0.3562\n",
      "Epoch 3/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310ms/step - accuracy: 0.9860 - loss: 0.0556 - val_accuracy: 0.9167 - val_loss: 0.1784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x263140d5730>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "cnn_model.fit(X_train_reshaped, y_train, epochs=3, batch_size=32, validation_data=(X_test_reshaped, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cae71316-9f12-4642-8aa9-594001100cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9132 - loss: 0.1931\n",
      "Model Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = cnn_model.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Model Accuracy: {accuracy[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "57e73b04-49e8-47de-a2ab-636753bc3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Language(Enum):\n",
    "    ENGLISH = 'en-US'\n",
    "    FRENCH = 'fr-FR'\n",
    "    GERMAN = 'de-DE'\n",
    "    ITALIAN = 'it-IT'\n",
    "    SPANISH = 'es-ES'\n",
    "    PORTUGUESE = 'pt-BR'\n",
    "    KOREAN = \"ko-KR\"\n",
    "    CHINESE_SIMPLIFIED = \"zh-CN\"\n",
    "    CHINESE_TRADITIONAL = \"zh-TW\"\n",
    "    JAPANESE = \"ja-JP\"\n",
    "    RUSSIAN = \"ru-RU\"\n",
    "    POLISH = \"pl-PL\"\n",
    "    UKRAINIAN = \"uk-UA\"\n",
    "    BULGARIAN = \"bg-BG\"\n",
    "    BENGALI = \"bn-BD\"\n",
    "    TURKISH = \"tr-TR\"\n",
    "    ARABIC = \"ar-SA\"\n",
    "    INDONESIAN = \"id-ID\"\n",
    "    THAI = \"th-TH\"\n",
    "    VIETNAMESE = \"vi-VN\"\n",
    "    MALAY = \"ms-MY\"\n",
    "    HINDI = \"hi-IN\"\n",
    "    PUNJABI = \"pa-IN\"\n",
    "    TELUGU = \"te-IN\"\n",
    "    GUJARATI = \"gu-IN\"\n",
    "    ORIYA = \"or-IN\"\n",
    "    MARATHI = \"mr-IN\"\n",
    "    SINDHI = \"sd-IN\"\n",
    "    TAMIL = \"ta-IN\"\n",
    "    KANNADA = \"kn-IN\"\n",
    "    MALAYALAM = \"ml-IN\"\n",
    "    ASSAMESE = \"as-IN\"\n",
    "    ODIA = \"or-IN\"\n",
    "    SANSKRIT = \"sa-IN\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "df9bbd26-3b1a-4087-b4c7-3992c37bc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech to Text Class\n",
    "class SpeechToText:\n",
    "    @staticmethod\n",
    "    def speech_to_text(device_index=1, language=Language.ENGLISH):\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone(device_index=device_index) as source:\n",
    "            print(\"Recording...\")\n",
    "            audio = r.listen(source)\n",
    "            print(\"Recording Complete...\")\n",
    "\n",
    "            try:\n",
    "                # Transcribe audio to text\n",
    "                text = r.recognize_google(audio, language=language.value)\n",
    "                return text\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio\")\n",
    "                return None\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Request error from Google Speech Recognition service; {0}\".format(e))\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "df52738d-f781-4a94-b7fa-0034a69ea581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the language from audio\n",
    "def predict_language_from_audio(device_index=1, language=Language.ENGLISH):\n",
    "    transcribed_text = SpeechToText.speech_to_text(device_index, language)\n",
    "    \n",
    "    if transcribed_text:\n",
    "        # Transform the transcribed text to feature vector\n",
    "        data = cv.transform([transcribed_text]).toarray()\n",
    "        \n",
    "        # Reshape the data for the model (since CNN expects 3D input)\n",
    "        data_reshaped = data.reshape((data.shape[0], data.shape[1], 1))\n",
    "        \n",
    "        # Get the model's prediction\n",
    "        output = cnn_model.predict(data_reshaped)\n",
    "        \n",
    "        # Get the label with the highest probability\n",
    "        predicted_label = np.argmax(output)\n",
    "        \n",
    "        # Convert to original language name using the label encoder\n",
    "        predicted_language = label_encoder.inverse_transform([predicted_label])\n",
    "        \n",
    "        print(f\"Predicted Language: {predicted_language[0]}\")\n",
    "    else:\n",
    "        print(\"No transcribed text received.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d9d3e87-65cf-4f7f-82d9-3014fbd36575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording Complete...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "Predicted Language: Tamil\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    device_index = 1  # Set device index based on available microphones\n",
    "    language = Language.ENGLISH  # Set language to English for recognition\n",
    "    predict_language_from_audio(device_index=device_index, language=language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d5f43-9897-435c-80bf-29a37ff46ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
